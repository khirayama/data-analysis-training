## Overview & Progress

- [ ] Pythonの導入
  - [ ] Pythonとは
  - [ ] 開発環境の構築について
    - [ ] ローカルにAnacondaを使って環境構築
    - [ ] Google Colaboratoryで環境構築
  - [ ] Pythonの基本的な使い方
    - [ ] 算術演算
    - [ ] 比較演算子
    - [ ] データ型
    - [ ] リスト
    - [ ] タプル
    - [ ] 辞書
    - [ ] 条件分岐
    - [ ] 関数定義
    - [ ] ループ処理
    - [ ] リスト内包表記
- [ ] Pythonを使ったデータ処理
  - [ ] ライブラリのインストール
  - [ ] Numpyライブラリの使い方
    - [ ] numpy基礎
    - [ ] 要素へのアクセス
    - [ ] 演算
    - [ ] いろいろな初期化
  - [ ] Pandasの使い方
    - [ ] Series
    - [ ] DataFrame
    - [ ] 便利なメソッド
    - [ ] データの読み込み
  - [ ] Pythonの可視化ライブラリ
    - [ ] ヒストグラム
    - [ ] 散布図
    - [ ] 折れ線グラフ
    - [ ] その他
  - [ ] データ分析の流れ
    - [ ] データを集める
    - [ ] 前処理(データ整形)
    - [ ] 分析
    - [ ] 評価方法
    - [ ] 考察
- [ ] 教師あり〜回帰〜
  - [ ] 線形回帰
    - [ ] 回帰分析
    - [ ] 線形回帰分析のイメージ
    - [ ] 重回帰分析のイメージ
    - [ ] パラメータの導出
    - [ ] 連続値ではない変数
    - [ ] 実践編1(ボストン市内の地域別住宅価格データ)
    - [ ] 実践編2(東京都の不動産価格データ)
  - [ ] リッジ回帰・ラッソ回帰
    - [ ] 過学習
    - [ ] ラッソ回帰
    - [ ] リッジ回帰
    - [ ] ラッソ回帰とリッジ回帰の効果
    - [ ] 実践編1(ボストン市内の地域別住宅価格データ)
    - [ ] 実践編2(東京都の不動産価格データ)
- [ ] 教師あり〜分類〜
  - [ ] ロジスティック回帰
    - [ ] 分類とは
    - [ ] 線形回帰で解こうとしてみる
    - [ ] ロジスティック回帰
    - [ ] 実践編1(irisデータ)
    - [ ] 実践編2(Tweetデータ)
  - [ ] 決定木
    - [ ] 決定木とは
    - [ ] 不純度の考え
    - [ ] 決定木と剪定
    - [ ] 実践編1(irisデータ)
    - [ ] 実践編2(Tweetデータ)
  - [ ] ランダムフォレスト
    - [ ] バギングとは
    - [ ] ランダムフォレスト
    - [ ] 実践編1(irisデータ)
    - [ ] 実践編2(Tweetデータ)
- [ ] 
  - [ ] 
    - [ ] 
    - [ ] 
    - [ ] 
    - [ ] 
  - [ ] 
    - [ ] 
    - [ ] 
    - [ ] 
    - [ ] 
- [ ] 
  - [ ] 
    - [ ] 
    - [ ] 
    - [ ] 
    - [ ] 
    - [ ] 
    - [ ] 
  - [ ] 
    - [ ] 
    - [ ] 
    - [ ] 
    - [ ] 
    - [ ] 
    - [ ] 
    - [ ] 
- [ ] 
  - [ ] 
    - [ ] 
    - [ ] 
    - [ ] 
    - [ ] 
    - [ ] 
    - [ ] 
    - [ ] 
  - [ ] 
    - [ ] 
    - [ ] 
    - [ ] 
    - [ ] 
    - [ ] 
- [ ] 
  - [ ] 
    - [ ] 
    - [ ] 
    - [ ] 
    - [ ] 
    - [ ] 
    - [ ] 
  - [ ] 
    - [ ] 
    - [ ] 
    - [ ] 
    - [ ] 
    - [ ] 
- [ ] 
  - [ ] 
  - [ ] 
  - [ ] 

## Steps

- データを集める
- 前処理
- 分析
- 評価
- 考察

- とりあえずdataFrameに打ち込む
- データをちゃんと読む
- グラフとかにして関係をみてみる

## ざっくり用語

- 訓練誤差: 学習データでの精度。
- 汎化誤差: 未知データでの精度。
- 過学習: 訓練誤差で評価がよく、汎化誤差で評価が悪い状態。
- 正則化: パラメータに制約を課すこと。それにより過学習を防いだりする。
- ラッソ回帰: L1正則化(パラメータの絶対値の和を用いた正則化)項を用いた回帰
- リッジ回帰: L2正則化(パラメータの絶対値の二乗和を用いた正則化)項を用いた回帰

## Memo

- Juypter Notebookで補完ってできないの...？
- JupyterLabというのがあるらしい
- VSCodeでもできるっぽい？
